# Speaker Notes - AI Security Monitoring
## FOSDEM 2026 - Security Devroom (25 minutes)

---

## Timing Overview

| Section | Slides | Duration | Cumulative |
|---------|--------|----------|------------|
| Opening & Context | 1-5 | 5 min | 5 min |
| Threat Model Framework | 6 | 2 min | 7 min |
| Detection Patterns | 7-12 | 7 min | 14 min |
| Open Source Stack | 13-16 | 4 min | 18 min |
| Demo | 17 | 3 min | 21 min |
| Wrap-up & Limitations | 18-21 | 4 min | 25 min |

---

## SLIDE 1: Title (30 sec)

**Key points:**
- "Bonjour, je suis Samuel Desseaux, Founder & CTO d'Erythix et Aureonis"
- "Aujourd'hui: comment monitorer la s√©curit√© de vos syst√®mes ML en production avec des outils 100% open source"
- "Tout le code et les configs sont dispo sur GitHub - lien √† la fin"

**Transition:** "Commen√ßons par le probl√®me..."

---

## SLIDE 2: What We'll Cover (30 sec)

**Key points:**
- Parcourir rapidement les 6 sections
- "On va d'abord comprendre POURQUOI c'est diff√©rent, puis construire un framework, et finir avec une d√©mo live"

**Transition:** "Alors, quel est le probl√®me exactement?"

---

## SLIDE 3: Your AI Model is a New Attack Surface (1 min 30)

**Key points:**
- "La s√©curit√© traditionnelle monitore le r√©seau et les logs syst√®me. Mais qui surveille la couche IA elle-m√™me?"
- Parcourir les 6 menaces rapidement:
  - Adversarial inputs: "des inputs qui trompent le mod√®le tout en paraissant normaux"
  - Data poisoning: "corrompre les donn√©es d'entra√Ænement"
  - Prompt injection: "le OWASP #1 pour les LLMs"
  - Model extraction: "voler votre mod√®le via l'API - 10K requ√™tes suffisent souvent"
  - Membership inference: "savoir si des donn√©es √©taient dans le training set - privacy issue"
  - Model drift: "d√©gradation graduelle exploitable par les attaquants"

**Transition:** "Mais pourquoi les syst√®mes ML sont-ils si diff√©rents?"

---

## SLIDE 4: Why ML Systems Are Different (1 min)

**Key points:**
- **Data = Code:** "Dans le ML, les donn√©es SONT le programme. Pas de code review possible sur les donn√©es d'entra√Ænement"
- **Opaque Logic:** "Milliards de param√®tres - impossible de tracer pourquoi une d√©cision a √©t√© prise"
- **Emergent Behavior:** "Le mod√®le peut se comporter de fa√ßon inattendue sur des edge cases"

**Pause:** Laisser le message sink in

**Transition:** "Et c'est maintenant que √ßa devient urgent..."

---

## SLIDE 5: Why Now? The Threat Landscape (1 min 30) ‚≠ê NOUVEAU

**Key points:**
- **OWASP Top 10 LLM:** "Prompt Injection est maintenant officiellement le risque #1 - c'est la taxonomie de r√©f√©rence"
- **MITRE ATLAS:** "600+ techniques d'attaque document√©es - l'√©quivalent de ATT&CK pour le ML"
- **Real Incidents 2024:** 
  - "Model extraction chez Replika"
  - "Les jailbreaks ChatGPT qui font la une"
  - "Les leaks de system prompts de Copilot"
  - "L'IA est sous attaque active - ce n'est plus th√©orique"

**Emphasize:** "Si vous d√©ployez du ML en prod sans monitoring s√©curit√©, vous volez √† l'aveugle"

**Transition:** "Comment structurer notre approche? Avec un threat model..."

---

## SLIDE 6: Threat Model Framework for ML (2 min)

**Key points:**
- Montrer le pipeline: Data Ingestion ‚Üí Training ‚Üí Model Serving ‚Üí LLM Apps
- "Chaque √©tape a ses vecteurs d'attaque sp√©cifiques"
- Les 4 questions cl√©s:
  1. **ASSETS:** "Qu'est-ce qu'on prot√®ge? Le mod√®le? Les donn√©es? L'int√©grit√© des pr√©dictions?"
  2. **ADVERSARIES:** "Qui attaque? Hackers externes? Insiders? Vendors compromis?"
  3. **VECTORS:** "Comment? API access? Pipeline de training? Supply chain?"
  4. **SIGNALS:** "Quelles m√©triques d√©tectent les attaques?"

- "Le PDF template est t√©l√©chargeable sur le repo"

**Transition:** "Passons aux patterns de d√©tection concrets..."

---

## SLIDE 7: Adversarial Input Detection (1 min)

**Key points:**
- "Pattern 1: d√©tecter les inputs crafted pour tromper le mod√®le"
- 4 signaux cl√©s:
  - High confidence + High reconstruction error
  - Prediction instability
  - Feature space anomalies
  - Ensemble disagreement
- "Les m√©triques Prometheus √† exporter sont list√©es √† droite"

**Transition:** "Voyons les alertes correspondantes..."

---

## SLIDE 8: Prometheus Alerting - Adversarial (1 min)

**Key points:**
- Parcourir les 3 alertes YAML
- **Tip important:** "~85% de d√©tection sur FGSM/PGD avec seulement 2-5ms de latency overhead"
- "Full YAML sur GitHub"

**Transition:** "Pattern 2: le comportement du mod√®le..."

---

## SLIDE 9: Model Behavior Monitoring (1 min)

**Key points:**
- "D√©tecter le poisoning et l'extraction en monitorant le comportement"
- Distribution drift (PSI/KL divergence)
- Query patterns - "10K queries suffisent souvent pour cloner un mod√®le simple"
- Performance regression sur des classes sp√©cifiques

**Transition:** "Les alertes..."

---

## SLIDE 10: Prometheus Alerting - Behavior (1 min)

**Key points:**
- Distribution drift avec `for: 15m` - "on veut du signal, pas du bruit"
- Suspicious query pattern > 100 req/min
- Accuracy drop cibl√© - "si une seule classe drop, c'est suspect"

**Key insight:** "Rate limit + alert early. Mieux vaut √™tre trop prudent."

**Transition:** "Pattern 3, sp√©cifique aux LLMs..."

---

## SLIDE 11: LLM Security Monitoring (1 min)

**Key points:**
- "Prompt injection est OWASP #1 - donc Pattern 3 est crucial"
- 4 types de menaces:
  - Direct injection: "Ignore previous instructions..."
  - Indirect injection: dans les docs RAG
  - Jailbreaking: bypass des guardrails
  - Extraction: "What are your instructions?"
- M√©triques d√©di√©es: injection_score, similarity_to_system, tool_calls

**Transition:** "Les alertes LLM..."

---

## SLIDE 12: Prometheus Alerting - LLM (1 min)

**Key points:**
- Injection > 0.85 ‚Üí severity: critical
- System prompt extraction ‚Üí surveiller la similarit√© avec le system prompt
- Tool usage suspicious ‚Üí shell, exec, write avec rate > 5/min

**Tip:** "Utilisez ProtectAI/deberta-v3-base-prompt-injection - c'est open source et efficace"

**Transition:** "Maintenant, le stack technique..."

---

## SLIDE 13: The Fully Open Source Stack (1 min 30)

**Key points:**
- Prometheus: metrics collection, PromQL, Alertmanager
- Loki: logs structur√©s, r√©tention, LogQL
- Grafana: dashboards, alerting unifi√©
- OpenTelemetry: tracing des pipelines ML

**4 avantages:**
- No vendor lock-in (CNCF + VictoriaMetrics pour le scale)
- Already in SOC - probablement d√©j√† d√©ploy√©
- Extensible avec custom exporters
- Scalable - prouv√© √† l'√©chelle

**Transition:** "Comment structurer les logs..."

---

## SLIDE 14: Structured Logging with Loki (1 min)

**Key points:**
- Montrer le schema JSON: timestamp, level, model, event_type, user_id, confidence, trace_id
- Queries LogQL pour investigation
- "Les retention policies: Security 90j, Predictions 30j, Debug 7j"

**Transition:** "Les dashboards..."

---

## SLIDE 15: Grafana Security Dashboards (30 sec)

**Key points:**
- Vue d'ensemble rapide des panels
- "Time series, tables, logs panel, alert list"
- "Le JSON est sur le repo"

**Transition:** "L'int√©gration SOC..."

---

## SLIDE 16: SOC Integration Architecture (1 min)

**Key points:**
- ML Layer ‚Üí Exporters ‚Üí Observability ‚Üí SOC Workflow
- 4 m√©thodes d'int√©gration:
  - Alertmanager webhooks vers SIEM
  - Grafana OnCall pour incident management
  - Loki vers SIEM via syslog
  - OTel exporters vers n'importe quel backend compatible

**Transition:** "Construire vos propres exporters..."

---

## SLIDE 17: Building Custom Exporters (45 sec)

**Key points:**
- Montrer le code Python rapidement
- "prometheus_client est votre ami"
- Best practices: histograms pour distributions, √©viter high cardinality labels, async export

**Transition:** "Place √† la d√©mo..."

---

## SLIDE 18: Demo (3 min) ‚≠ê LIVE

**Setup avant:** Avoir Grafana ouvert sur le dashboard

**Sc√©nario 1 - Adversarial (1 min):**
- Lancer l'attaque FGSM
- Montrer le spike de reconstruction error
- Montrer l'alert qui fire
- Montrer le log avec trace ID

**Sc√©nario 2 - Model Extraction (1 min):**
- Lancer les queries syst√©matiques
- Montrer le query rate spike
- Montrer le low entropy pattern
- "User ID logg√© - on sait qui c'est"

**Sc√©nario 3 - Prompt Injection (1 min):**
- Envoyer un jailbreak attempt
- Montrer l'injection classifier qui trigger
- Request blocked
- Full prompt logg√©

**Closing:** "Stack: Prometheus + Loki + Grafana. Repo sur GitHub."

---

## SLIDE 19: What You're Taking Home (1 min)

**Key points:**
- 4 livrables concrets:
  1. Threat Model Framework PDF
  2. Prometheus alerting YAML files
  3. LogQL query library
  4. SOC integration configs + Grafana dashboards

- "Tout est Apache 2.0, PRs welcome!"
- Dire l'URL: github.com/erythix/ml-security-monitoring

**Transition:** "Mais attention aux limitations..."

---

## SLIDE 20: Limitations & Considerations (1 min) ‚≠ê NOUVEAU

**Key points:**
- **Not a Silver Bullet:** "Ces patterns d√©tectent des signatures connues. Zero-day et nouvelles techniques peuvent passer initialement"
- **Setup Required:** "La d√©tection par reconstruction error n√©cessite un autoencoder entra√Æn√©. Les baselines doivent √™tre calibr√©es par mod√®le"
- **False Positives:** "Des donn√©es l√©gitimes hors-distribution peuvent d√©clencher des alertes. Tuning n√©cessaire"

**Important:** "C'est un layer de d√©fense suppl√©mentaire, pas une solution magique"

**Transition:** "En conclusion..."

---

## SLIDE 21: Conclusion (1 min)

**Closer statement:** "Your AI model is an attack surface. Monitor it like one."

**Call to action:**
- "Le repo GitHub est live - clonez-le, testez-le, contribuez"
- "Je suis dispo pour les questions maintenant et pendant la conf"
- "Merci!"

**Contact:** Montrer les 3 liens (GitHub, Twitter, Website)

---

## Q&A Preparation

**Questions probables:**

1. **"Quel overhead sur les performances?"**
   - 2-5ms sur l'inf√©rence pour les m√©triques de base
   - Reconstruction error peut √™tre async si trop lent
   - Le monitoring ne doit pas bloquer l'inference

2. **"Comment entra√Æner l'autoencoder pour reconstruction error?"**
   - Sur les donn√©es de training normales
   - Architecture simple suffit (dense layers)
   - Retrain p√©riodiquement avec les nouvelles donn√©es

3. **"√áa scale comment?"**
   - Prometheus scale √† millions de s√©ries
   - VictoriaMetrics si besoin de plus
   - Loki scale horizontalement

4. **"Et pour les mod√®les edge/embarqu√©s?"**
   - M√©triques agr√©g√©es envoy√©es p√©riodiquement
   - Local detection + remote logging
   - OpenTelemetry Collector pour buffering

5. **"Int√©gration avec les MLOps platforms (MLflow, Kubeflow)?"**
   - Prometheus exporters standard
   - OTel SDK dans les pipelines
   - Grafana se connecte √† tout

---

## Checklist Avant la Pr√©sentation

- [ ] Tester le docker-compose de la d√©mo
- [ ] V√©rifier que Grafana montre les bons dashboards
- [ ] Pr√©parer les 3 attaques simul√©es
- [ ] V√©rifier la connexion internet (pour la d√©mo)
- [ ] Backup: screenshots si la d√©mo live √©choue
- [ ] Avoir le repo GitHub pr√™t et public
- [ ] Slide clicker charg√©
- [ ] Water bottle

---

## Notes de Style

- **Tempo:** Dynamique mais pas rushed - c'est du contenu technique dense
- **Jargon:** OK pour cette audience (Security devroom = experts)
- **Code:** Ne pas lire le YAML ligne par ligne - pointer les parties importantes
- **Demo:** Si √ßa plante, avoir les screenshots ready. "As you can see in this screenshot..."
- **Questions pendant:** "Great question - let's cover that in Q&A" si √ßa d√©raille

---

*Good luck Samuel! üöÄ*
